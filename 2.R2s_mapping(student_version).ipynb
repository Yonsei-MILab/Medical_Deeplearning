{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2.R2s_mapping(student_version).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"4j1oJ61DXwOT","colab_type":"text"},"source":["# TASK 2. R2* Mapping (Multi-Layer Perceptron)\n","\n","### **We are going to train the MLP to estimate the R2* of each voxel using MRI data. The overall procedure is following:**\n","\n","> **1. Data preparation**  \n","**2. define the network architecture**  \n","**3. train the network**  \n","**4. test the trianed network**  \n","\n","\n","![ ](https://blogfiles.pstatic.net/MjAxOTA5MTBfMTUw/MDAxNTY4MTAzNDExNjEx.1mLJ0eR2qgTUql3Rg8eZ52urXAvz1z5aaK39xmp3JEUg.ccAfmkXluOlasS80oOtOsxEN-ZTqyf5mjsVLGUM_R7Ig.PNG.susie1513/process.png)\n","\n"]},{"cell_type":"code","metadata":{"id":"SI_A2MQx7Get","colab_type":"code","colab":{}},"source":["# import libraries\n","# don't forget to do drive mount for data loading\n","\n","import torch \n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","import torch.nn.functional as F\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from scipy import io\n","import h5py"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dmu5ssrLYHos","colab_type":"text"},"source":["# 1. Data Preparation \n","\n","### First, we have to load the MRI simulation data. Since collecting wide range of in vivo signals is difficult, we use simulation data for training. For simulation data, mono-exponential decay is used with following ranges of input variables : A ∈ [0.8,0.81,...,1.5] ,  T2 * ∈ [10,11,...299,300,310,...,1500] ms.\n","\n","\n","![ ](https://postfiles.pstatic.net/MjAxOTA5MTBfMjgx/MDAxNTY4MTAzMTA3MDQy.qeHFDVnYxIaGpHot_2aMCeDK5NhnzB7vyyrhwBBROZ0g.uVvsJRE-M1Jj4ivhIxZCU3aph0tm4kVNQacevDnL1wwg.PNG.susie1513/monodecay.png?type=w580\n",")"]},{"cell_type":"code","metadata":{"id":"Hq6JMG0U7I9z","colab_type":"code","colab":{}},"source":["f = h5py.File('/content/drive/My Drive/Colab Notebooks/TASK2.Data/train_R2s.h5', 'r')\n","\n","X_train = f['X_train']\n","X_train = np.float32(X_train)\n","X_train = torch.from_numpy(X_train)\n","\n","Y_train = f['Y_train']\n","Y_train = np.float32(Y_train)\n","Y_train = torch.from_numpy(Y_train)\n","\n","print(X_train.shape)\n","print(Y_train.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4v5E7F-xi5-f","colab_type":"text"},"source":["# 2. Define the network architecture \n","\n","### Now we will define our own network architecture. The network takes a 11 echo MRI signals, and yields R2* value of each voxel. We used mean-squared-error which is commonly adopted in regression problems.\n","\n","\n","![ ](https://postfiles.pstatic.net/MjAxOTA5MTFfMjY2/MDAxNTY4MTk4MTMwMjkx.G7TvEFeAXjt6Wmd6mcAgrRxQOsuC6XV7CCyfZmi9LHgg.IEoWPd7JFZMrips8uNxdwbSiK1v364n96szYfOmmqMwg.PNG.susie1513/networks.png?type=w580\n",")\n"]},{"cell_type":"code","metadata":{"id":"tvjsCbIxsiUK","colab_type":"code","colab":{}},"source":["use_cuda = torch.cuda.is_available()\n","print(use_cuda)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7aqbYtKS8PxF","colab_type":"code","colab":{}},"source":["class R2s_model(nn.Module):\n","    \n","    def __init__(self):\n","        super(R2s_model, self).__init__()       \n","        # @@@ 'fc1' 레이어 정의 11 → 300 로 가는 layer @@@\n","        # @@@ 'fc2' 레이어 정의 300 → 300 로 가는 layer @@@\n","        # @@@ 'fc3' 레이어 정의 300 → 1 로 가는 layer @@@\n","        \n","        # gpu setting\n","        if use_cuda:\n","            self.fc1 = self.fc1.cuda()\n","            self.fc2 = self.fc2.cuda()\n","            self.fc3 = self.fc3.cuda()\n","        \n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))       \n","        x = F.relu(self.fc2(x))\n","        x = nn.Sigmoid()(self.fc3(x))\n","        return x\n","    \n","# @@@ 모델을 'model' 변수에 선언 @@@ \n","print(model)\n","\n","# loss function\n","criterion = nn.MSELoss()\n","\n","# optimizer\n","optimizer = optim.Adam(model.parameters(), lr = 1e-4)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uloM1yDwQ0sd","colab_type":"text"},"source":["# 3. Train the network\n","\n","### The steps for training are \n","\n","\n","\n","> **1. Clear the gradients of all variables**  \n","**2. Compute the predicted outputs by passing foward inputs to the model (forward pass)**  \n","**3. Calcuate the loss using the loss function that we defined**  \n","**4. Compute the gradient of the loss**  \n","**5. Perform a single optimization step**"]},{"cell_type":"code","metadata":{"id":"iFwpmZ_D9ag9","colab_type":"code","colab":{}},"source":["batch_size = 5000\n","n_batches = X_train.shape[0]//batch_size\n","n_epoch = 200\n","\n","plot_loss = []\n","\n","# @@@ 'model' training 선언 @@@\n","\n","for epoch in range(n_epoch):\n","    \n","    train_loss = 0.0  \n","    iteration = 0\n","        \n","    for ii in range(n_batches):\n","\n","        x_train = Variable(X_train[ii*batch_size:(ii+1)*batch_size,:], requires_grad = True)\n","        y_train = Variable(Y_train[ii*batch_size:(ii+1)*batch_size,:], requires_grad = True)\n","      \n","        if use_cuda:\n","            x_train = x_train.cuda()\n","            y_train = y_train.cuda()\n","        \n","        # 1. clear the gradients of all optimized variables\n","        optimizer.zero_grad()\n","        \n","        # 2. forward pass\n","        # @@@ input 데이터('x_train')를 model foward pass한 'res_x' 변수에 출력 @@@\n","        \n","        # 3. calculate the loss\n","        loss = criterion(res_x, y_train)\n","        \n","        # 4. backward pass\n","        # @@@ loss backpropagation 으로 각 변수들의 gradient 구하기 @@@\n","        \n","        # 5. parameter update\n","        # @@@ optimizer 로 parameter update @@@\n","        \n","        # update training loss\n","        # @@@ loss의 값을 'train_loss'에 더해주기 @@@\n","        iteration += 1\n","        \n","    # calculate average loss over one epoch    \n","    # @@@ 한 epoch 의 평균 loss를 'train_loss'에 overwrite @@@\n","    \n","    if (epoch+1)%5 == 0 :\n","      print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AynF5VZlQ4Vl","colab_type":"text"},"source":["# 4. Test the trained network\n","\n","### We test our model on unseen In vivo data and compared with conventional method."]},{"cell_type":"code","metadata":{"id":"skXdfLaO-mb8","colab_type":"code","colab":{}},"source":["# load test in vivo dataset\n","meas = io.loadmat('/content/drive/My Drive/Colab Notebooks/exercise_ANN/test_data_mgre.mat')\n","meas = meas['meas']\n","yy,xx,zz,ee = meas.shape\n","\n","# Input normalization\n","meas2 = np.zeros([yy,xx,zz,ee])\n","for i in range(yy):\n","    for j in range(xx):\n","        for k in range(zz):\n","            meas2[i,j,k,:] = meas[i,j,k,:]/meas[i,j,k,0]   \n","            \n","print(meas2.shape)\n","\n","# make the in vivo image to 2D torch array for network input\n","meas3 = np.reshape(meas2,[yy*xx*zz,ee])\n","meas3 = np.float32(meas3)\n","meas4 = torch.from_numpy(meas3)\n","\n","# @@@ model 을 평가하겠다고 선언 @@@\n","\n","# @@@ 'use_flag'가 True 이면' @@@\n","# @@@ test할 'meas4' gpu 선언 (if문 사용) @@@\n","\n","# get outputs\n","# @@@ network input에 맞게 변형시킨 test data 의 model output 'res_temp' 변수에 선언 @@@\n","\n","# perpare images for display\n","res_temp = res_temp.data.cpu().numpy()\n","\n","# reshape the result to 3D image \n","R2 = np.reshape(res_temp,[yy,xx,zz])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nVnecOqkUYE7","colab_type":"code","colab":{}},"source":["# load conventional fitting result to compare\n","label = io.loadmat('/content/drive/My Drive/Colab Notebooks/exercise_ANN/test_label_r2s.mat')\n","R2_true = label['R2']\n","\n","# plot the images with conventional method and the differences of two images\n","fig = plt.figure(figsize=(20, 7))\n","\n","nslice = 10\n","R2_pred_show = np.squeeze(R2[:,:,nslice-1:nslice])*100\n","R2_label_show = np.squeeze(R2_true[:,:,nslice-1:nslice])\n","\n","ax = fig.add_subplot(1, 3, 1, xticks=[], yticks=[])\n","ax.imshow(np.squeeze(R2_pred_show), cmap='gray',vmin=0,vmax=100)\n","ax.set_title(\"DL R2\")\n","\n","ax = fig.add_subplot(1, 3, 2, xticks=[], yticks=[])\n","ax.imshow(np.squeeze(R2_label_show), cmap='gray',vmin=0,vmax=100)\n","ax.set_title(\"Fitting R2\")\n","\n","ax = fig.add_subplot(1, 3, 3, xticks=[], yticks=[])\n","ax.imshow(np.squeeze(np.abs(R2_pred_show-R2_label_show))*10, cmap='gray',vmin=0,vmax=100)\n","ax.set_title(\"|DL - Fitting|*10\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6M2I2A_bUKuK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}